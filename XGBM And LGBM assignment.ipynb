{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fb67b8-6eba-4730-bbed-baccfae0cb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "!pip install xgboost\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0201d59-576b-46ee-a002-e5b9bc026a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "try:\n",
    "    df_train = pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\Titanic_train.csv\")\n",
    "    df_test = pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\Titanic_test.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find the datasets. Please ensure the file paths are correct.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de7bae4-42da-48d7-a999-57d6636eb3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "Missing values in testing data:\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in training data:\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "print(\"Missing values in testing data:\")\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "501569f7-eafc-40f2-be67-a0682aca90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "# Load datasets\n",
    "import pandas as pd\n",
    "try:\n",
    "    df_train = pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\Titanic_train.csv\")\n",
    "    df_test = pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\Titanic_test.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find the datasets. Please ensure the file paths are correct.\")\n",
    "    exit()    \n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_train['Age'] = imputer.fit_transform(df_train[['Age']])\n",
    "df_test['Age'] = imputer.transform(df_test[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd22a166-5195-409a-894d-90e3bebafab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_7176\\3290223031.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_7176\\3290223031.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test['Fare'].fillna(df_test['Fare'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_train['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)\n",
    "df_test['Fare'].fillna(df_test['Fare'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "964d2f12-af78-4900-ae57-da6f260a7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['Cabin'], inplace=True)\n",
    "df_test.drop(columns=['Cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0a7d75c-7236-441f-8af4-297a14353367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "df_train = pd.get_dummies(df_train, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Sex', 'Embarked'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3824f90-431f-40a8-a139-99bcc124a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the same columns in both datasets\n",
    "for col in df_train.columns:\n",
    "    if col not in df_test.columns:\n",
    "        df_test[col] = 0\n",
    "\n",
    "for col in df_test.columns:\n",
    "    if col not in df_train.columns:\n",
    "        df_train[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9eef1b69-266f-40f8-a580-d812496bcfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns to match exactly\n",
    "df_train = df_train[df_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae1e1bc4-16b1-4c8f-bb49-d0dd120f8753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are not useful for the model\n",
    "df_train.drop(columns=['Name', 'Ticket'], inplace=True)\n",
    "df_test.drop(columns=['Name', 'Ticket'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95a6a779-10a7-4398-83c2-3cb00a8b463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features_to_scale = ['Age', 'Fare']\n",
    "df_train[features_to_scale] = scaler.fit_transform(df_train[features_to_scale])\n",
    "df_test[features_to_scale] = scaler.transform(df_test[features_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04999e0e-e7d4-401c-96b2-4771751e326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable from the features\n",
    "try:\n",
    "    X_train = df_train.drop(columns=['Survived'])\n",
    "    y_train = df_train['Survived']\n",
    "\n",
    "    X_test = df_test.drop(columns=['Survived'])\n",
    "    y_test = df_test['Survived']\n",
    "except KeyError as e:\n",
    "    print(f\"Error: {e} not found in the dataset columns.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f950193e-25ec-48a9-a6fe-d087aceb9535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 342, number of negative: 549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 478\n",
      "[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288\n",
      "[LightGBM] [Info] Start training from score -0.473288\n"
     ]
    }
   ],
   "source": [
    "# Build predictive models\n",
    "import lightgbm as lgb\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "616b9697-13aa-4113-bf05-1eb0d592e770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68b7cea9-9e7d-4b4e-a95b-e9cd2c6da84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94c33f87-60fa-426e-b9eb-e0b1c1f15798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "    \n",
    "lgb_results = evaluate_model(y_test, y_pred_lgb)\n",
    "xgb_results = evaluate_model(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9dd1d89d-c47f-433f-8f4a-8c437031463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Results: Accuracy=0.6626794258373205, Precision=0.0, Recall=0.0, F1-score=0.0\n",
      "XGBoost Results: Accuracy=0.6674641148325359, Precision=0.0, Recall=0.0, F1-score=0.0\n"
     ]
    }
   ],
   "source": [
    "print(f'LightGBM Results: Accuracy={lgb_results[0]}, Precision={lgb_results[1]}, Recall={lgb_results[2]}, F1-score={lgb_results[3]}')\n",
    "print(f'XGBoost Results: Accuracy={xgb_results[0]}, Precision={xgb_results[1]}, Recall={xgb_results[2]}, F1-score={xgb_results[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d62ab-9157-4b1f-867a-3a20947b6370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
